# VirES server containers


## Prerequisites

### Install podman

To run the container-based VirES development server make sure `podman`
is installed on your computer.


### Creating instance secrets

Before starting the VirES pod/containers random instance secrets must be
generated by the provided script.  Namely, the secrets for the PosgreSQL
databases, Django session keys, and OAuth app client credentials.

```
./generate_secrets.sh
```

Once created, these secrets do not need be modified.

### Access to image repository

The VirES images are stored in a private repository which require
access credentials. These credentials are not included in this repository.

It is not necessary to have access to the repository to be able to build
and use the container images. 

If you need the access credentials for the container repository contact
the VirES team.


## Quick start

Step 1, pull container images from the registry
```
./image pull_all
```
or build them from scratch
```
./image build_all
```

Step 2, run the pod containers
```
./pod create
```
and go to `http://localhost:8200` in your browser. Please note that it takes
some time to initialize the containers. Do not panic if the service shows
initially `503 Service Unavailable` it may not be initialized yet.
Give it a minute and try it again.

See below how to configure data location and register data.
How to get the data is not part of this guide.

## Container image hierarchy

 - `centos7` - Base CentOS 7 image
  - `database` - PosgreSQL DB server
  - `ingress` - Apache web server
  - `django-base` - common base Django image
    - `oauth-base` - base OAuth server
      - `oauth` - development OAuth server
    - `swarm-base` - base Swarm server image
      - `swarm` - development Swarm server image

Each of the container images has it is own directory with the container definitions.


## Understanding the container life-cycle

The VirES development setup uses a podman pod which binds a couple of separate
containers into a pod. Namely:

- database - PosgreSQL DB server container
- ingress - Web server publishing the static content and serving as a reverse proxy to the VirES services
- swarm - VirES Swarm application server
- ouath - VirES OAuth application server

Once created, the individual containers exist until removed manually.
These containers can be re-started and once running commands can be executed
in these containers.

In particular, they are not automatically replaces when newer built images appear.
To do so, the running containers must be stopped and removed first.
Then the newly created containers will use the up-to-date container images

This can be achieved by the provided helper scripts, e.g.,

```
./container swarm reload ; ./container swarm logs -f
```
(Note that the reload does not show any output. To see the container
initialization it is recommended to show the output of the podman logs)

## Container volumes

The containers use a mixture of named volumes and volumes mounded from
the host file-system (see the `./volumes` folder).

The named volumes attached to this pod can be listed by 
```
./volume list
```

The named volumes attached to this can be removed by
```
./volume remove
```

## Pod management

To start the pod run following script witch creates and start the pod
named `vires-server-dev` and bootstraps the required containers

```
./pod create
```

The status of the container can be checked by
```
./pod status
```

The containers and their status can be checked by
```
./pod ps
```

To restart pod, e.g., after the computer restart run
```
./pod restart
```

To remove the pod and all its containers run
```
./pod remove
```

## PosgreSQL database initialization and management

The database container is started without any database created. The database
and the associated roles need to be generated from the credentials.

```
./container database exec -i create_db < ./volumes/secrets/oauth.conf
./container database exec -i create_db < ./volumes/secrets/swarm.conf
```

The `start_pod.sh` command takes care of the databases but
it needs executed manually to force an update of the credentials.

In addition, a few helper commands are provide to manage the instance databases:

```
./container database exec list_dbs
./container database exec list_db_users
./container database exec drop_db <db-name>
./container database exec drop_db_user <db-user>
```


## Django instances

The `swarm` and `oauth` instances are initialized automatically upon container
creation do not require manual intervention.

Instance data are updated at each container creation (reload of the container)
```
./container swarm reload
```

To force update the of the Django persistent instance configuration
(e.g., settings.py) remove the instance and restart the container
```
rm -fR ./volumes/swarm/{manage.py,swarm} ; ./container swarm reload
```

Since the VirES server components are mounted from their local development
folders any changes are visible immediately in the container, though,
in order to take an effect the running daemons must be restarted.
This is achieved by restarting of the containers.
```
./container swarm restart
```

For a running container, the `manage.py` scripts can be executed as
```
./container swarm exec runuser -u vires manage.py
```

## Web client installation

The web client is installed from the `contrib/WebClient-Framework.tar.gz`
upon the reload of the `swarm` container.

## Data registration

To register products in batch run the following command
```
./container swarm exec register_products
```

This command scans for data products in the configured data directory
and registers them to the server.

Beside the batch registration you can control the registered data
by the `manage.py` command
```
./container swarm exec manage.py --help
```

### Data location

By default the `swarm` container mounts data from the `../../data` directory
(the same default location as of the Vagrant VM).

To change the default location, set `VIRES_DATA` environment variable and
reload the `swarm` container.

```
export VIRES_DATA=<your custom data directory>
./container swarm reload ; ./container swarm logs -f
```

## Building new containers

Before you start a new container build make sure you update the common
container tag in `tag.conf` file

```
IMAGE_TAG="20230725T1531"
```

Make the tag is set to the time-stamp produced by the following command
```
date -u +"%Y%m%dT%H%M"
```
though the tag name can be arbitrary and it is recommended to use own tag-name
to distinguish your build from the official ones.


The run the build scripts for the individual containers
```
./image <name> build
```

Or build all containers in one shot (skips existing containers).
```
./image build_all
```

Once build the containers can be pushed to the repository by
```
./image push_all
```
